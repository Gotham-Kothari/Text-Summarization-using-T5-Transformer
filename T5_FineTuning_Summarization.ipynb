{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd510d90-9f4a-4a6c-9aa1-2e9a324abe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:10%]\")\n",
    "\n",
    "def preprocess(example):\n",
    "  input_text = f\"summarize: {example['article']}\"\n",
    "  input_ids = tokenizer(input_text, padding = \"max_length\", truncation = True, return_tensors = \"tf\").input_ids[0]\n",
    "  target_ids = tokenizer(example['highlights'], padding = 'max_length', truncation = True, max_length = 64, return_tensors = 'tf').input_ids[0]\n",
    "  return {\"input_ids\": input_ids, \"labels\": target_ids}\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess)\n",
    "\n",
    "def generator():\n",
    "  for ex in tokenized_dataset:\n",
    "    yield {\"input_ids\": ex[\"input_ids\"], \"labels\": ex[\"labels\"]}\n",
    "\n",
    "import tensorflow as tf\n",
    "tf_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    output_signature = {\n",
    "        \"input_ids\": tf.TensorSpec(shape = (512, ), dtype = tf.int32),\n",
    "        \"labels\" : tf.TensorSpec(shape = (64,), dtype = tf.int32)\n",
    "    }\n",
    ").batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "from transformers import TFTrainingArguments\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True))\n",
    "\n",
    "model.fit(tf_dataset, epochs = 5)\n",
    "\n",
    "def generate_summary(text):\n",
    "    input_text = f\"summarize: {text.strip()}\"\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"tf\", padding=\"max_length\", truncation=True, max_length=512).input_ids\n",
    "\n",
    "    # Generate with better beam settings\n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=64,\n",
    "        num_beams=8,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=2\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "article = \"\"\"The Eiffel Tower is one of the most iconic landmarks in Paris. Built in 1889, \n",
    "it stands at over 300 meters tall and attracts millions of tourists every year. \n",
    "Originally constructed for the World's Fair, it was initially met with criticism but \n",
    "has since become a beloved symbol of France.\"\"\"\n",
    "\n",
    "summary = generate_summary(article)\n",
    "print(\"Generated Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF GPU)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
